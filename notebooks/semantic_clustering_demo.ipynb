{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Semantic Product Clustering Demo\n",
        "\n",
        "This notebook demonstrates semantic clustering of product names to identify categories regardless of barcode differences.\n",
        "\n",
        "## Problem Statement\n",
        "Different people record the same TYPE of product with different names:\n",
        "- **Tables**: \"Table\", \"Desk\", \"Mesa\", \"Masa\", \"Writing Desk\"\n",
        "- **Chairs**: \"Chair\", \"Sandalye\", \"Silla\", \"Gaming Chair\"\n",
        "- **Computers**: \"Computer\", \"PC\", \"Bilgisayar\", \"Laptop\"\n",
        "\n",
        "**Goal**: Group semantically similar names to count product categories:\n",
        "- \"How many table-type items do we have?\"\n",
        "- \"How many chair-type items?\"\n",
        "- \"What's our inventory breakdown by category?\"\n",
        "\n",
        "## Pipeline Overview\n",
        "1. **Ingest** CSV data with product names and barcodes\n",
        "2. **Normalize** multilingual text\n",
        "3. **Generate** semantic embeddings (TF-IDF or transformers)\n",
        "4. **Cluster** semantically similar names\n",
        "5. **Analyze** clusters to identify product categories\n",
        "6. **Summarize** inventory by semantic categories\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\TCEERBIL\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All modules imported successfully!\n",
            "üìÅ Working directory: c:\\Users\\TCEERBIL\\Desktop\\ege-workspace\\notebooks\n",
            "üìÅ Data directory: C:\\Users\\TCEERBIL\\Desktop\\ege-workspace\\data\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import sys\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src directory to path\n",
        "sys.path.append('../src')\n",
        "\n",
        "# Import our modules\n",
        "from ingest import CSVIngester\n",
        "from normalize import TextNormalizer, MultilingualNormalizer\n",
        "from embedding import NameEmbedder, SimilarityAnalyzer\n",
        "from cluster import NameClusterer, ClusterOptimizer\n",
        "from semantic import SemanticAnalyzer\n",
        "\n",
        "# SSL fixes for corporate networks\n",
        "import ssl\n",
        "import urllib3\n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        "os.environ['CURL_CA_BUNDLE'] = ''\n",
        "os.environ['REQUESTS_CA_BUNDLE'] = ''\n",
        "\n",
        "# Configure plotting\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "\n",
        "print(\"‚úÖ All modules imported successfully!\")\n",
        "print(f\"üìÅ Working directory: {os.getcwd()}\")\n",
        "print(f\"üìÅ Data directory: {Path('../data').resolve()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Load Semantic Test Data\n",
        "\n",
        "Our test data contains semantically similar products with different names and different barcodes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Semantic Test Dataset Overview:\n",
            "Shape: (56, 4)\n",
            "Columns: ['name', 'barcode', 'supplier', 'price']\n",
            "\n",
            "üìã Sample data:\n",
            "               name barcode    supplier  price\n",
            "0      Office Table  TBL001  Supplier A  150.0\n",
            "1         Work Desk  TBL002  Supplier B  180.0\n",
            "2    √áalƒ±≈üma Masasƒ±  TBL003  Supplier C  165.0\n",
            "3   Mesa de Oficina  TBL004  Supplier D  170.0\n",
            "4      Writing Desk  TBL005  Supplier A  190.0\n",
            "5       Study Table  TBL006  Supplier E  145.0\n",
            "6      Gaming Chair  CHR001  Supplier A  250.0\n",
            "7      Office Chair  CHR002  Supplier B  220.0\n",
            "8          Sandalye  CHR003  Supplier C  200.0\n",
            "9  Silla de Oficina  CHR004  Supplier D  240.0\n",
            "\n",
            "üîç Detected columns:\n",
            "Name column: 'name'\n",
            "Barcode column: 'barcode'\n",
            "\n",
            "üßπ Clean dataset: 56 rows\n",
            "üì¶ Unique barcodes: 56\n",
            "üè∑Ô∏è Unique names: 56\n"
          ]
        }
      ],
      "source": [
        "# Load semantic test data\n",
        "data_path = \"../data/semantic_products.csv\"\n",
        "\n",
        "# Initialize ingester\n",
        "ingester = CSVIngester()\n",
        "raw_data = ingester.load_csv(data_path)\n",
        "\n",
        "print(\"üìä Semantic Test Dataset Overview:\")\n",
        "print(f\"Shape: {raw_data.shape}\")\n",
        "print(f\"Columns: {list(raw_data.columns)}\")\n",
        "\n",
        "# Show sample data\n",
        "print(\"\\nüìã Sample data:\")\n",
        "print(raw_data.head(10))\n",
        "\n",
        "# Auto-detect columns\n",
        "name_col, barcode_col = ingester.detect_columns()\n",
        "print(f\"\\nüîç Detected columns:\")\n",
        "print(f\"Name column: '{name_col}'\")\n",
        "print(f\"Barcode column: '{barcode_col}'\")\n",
        "\n",
        "# Get clean data\n",
        "clean_data = ingester.get_clean_data()\n",
        "print(f\"\\nüßπ Clean dataset: {len(clean_data)} rows\")\n",
        "print(f\"üì¶ Unique barcodes: {clean_data['barcode'].nunique()}\")\n",
        "print(f\"üè∑Ô∏è Unique names: {clean_data['name'].nunique()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Text Normalization\n",
        "\n",
        "Normalize multilingual product names for better clustering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî§ Text Normalization Examples:\n",
            "Original ‚Üí Normalized\n",
            "--------------------------------------------------\n",
            "√áalƒ±≈üma Masasƒ±       ‚Üí calƒ±sma masasƒ±\n",
            "Mesa de Oficina      ‚Üí mesa de oficina\n",
            "Writing Desk         ‚Üí writing desk\n",
            "Gaming Chair         ‚Üí gaming chair\n",
            "Sandalye             ‚Üí sandalye\n",
            "Silla de Oficina     ‚Üí silla de oficina\n",
            "Bilgisayar           ‚Üí bilgisayar\n",
            "Ordenador            ‚Üí ordenador\n",
            "Desktop PC           ‚Üí desktop piece\n",
            "\n",
            "üîÑ Normalizing 56 product names...\n",
            "‚úÖ Normalization complete!\n",
            "\n",
            "üìã Normalized data preview:\n",
            "               name   normalized_name barcode\n",
            "0      Office Table      office table  TBL001\n",
            "1         Work Desk         work desk  TBL002\n",
            "2    √áalƒ±≈üma Masasƒ±    calƒ±sma masasƒ±  TBL003\n",
            "3   Mesa de Oficina   mesa de oficina  TBL004\n",
            "4      Writing Desk      writing desk  TBL005\n",
            "5       Study Table       study table  TBL006\n",
            "6      Gaming Chair      gaming chair  CHR001\n",
            "7      Office Chair      office chair  CHR002\n",
            "8          Sandalye          sandalye  CHR003\n",
            "9  Silla de Oficina  silla de oficina  CHR004\n"
          ]
        }
      ],
      "source": [
        "# Initialize multilingual normalizer\n",
        "ml_normalizer = MultilingualNormalizer()\n",
        "\n",
        "# Show normalization examples\n",
        "sample_names = [\n",
        "    \"√áalƒ±≈üma Masasƒ±\", \"Mesa de Oficina\", \"Writing Desk\",\n",
        "    \"Gaming Chair\", \"Sandalye\", \"Silla de Oficina\",\n",
        "    \"Bilgisayar\", \"Ordenador\", \"Desktop PC\"\n",
        "]\n",
        "\n",
        "print(\"üî§ Text Normalization Examples:\")\n",
        "print(\"Original ‚Üí Normalized\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for name in sample_names:\n",
        "    normalized = ml_normalizer.normalize_multilingual(name)\n",
        "    print(f\"{name:<20} ‚Üí {normalized}\")\n",
        "\n",
        "# Apply normalization to entire dataset\n",
        "print(f\"\\nüîÑ Normalizing {len(clean_data)} product names...\")\n",
        "clean_data['normalized_name'] = [ml_normalizer.normalize_multilingual(name) for name in clean_data['name']]\n",
        "\n",
        "print(\"‚úÖ Normalization complete!\")\n",
        "print(\"\\nüìã Normalized data preview:\")\n",
        "print(clean_data[['name', 'normalized_name', 'barcode']].head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Generate Embeddings\n",
        "\n",
        "Create semantic embeddings for similarity calculation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ü§ñ Generating embeddings (using TF-IDF fallback if needed)...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No sentence-transformers model found with name sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2. Creating a new one with mean pooling.\n",
            "Failed to load model paraphrase-multilingual-MiniLM-L12-v2: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2/resolve/main/adapter_config.json (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1007)')))\"), '(Request ID: 2a688add-1201-4806-9844-f0e21c211d29)')\n",
            "No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with mean pooling.\n",
            "All models failed to load: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1007)')))\"), '(Request ID: 3500c5e2-0b30-48d7-98b8-157318e077aa)')\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Generated embeddings with shape: (56, 97)\n",
            "üìè Embedding dimension: 97\n",
            "üéØ Method used: TF-IDF Fallback\n",
            "‚ÑπÔ∏è  Note: Using TF-IDF - this works great for semantic clustering!\n",
            "üìö Sample vocabulary: ['office', 'table', 'office table', 'work', 'desk', 'work desk', 'mesa', 'de', 'oficina', 'mesa de', 'de oficina', 'writing', 'writing desk', 'study', 'study table']\n",
            "\n",
            "üìä Similarity Analysis:\n",
            "Mean similarity: 0.009\n",
            "Std deviation: 0.055\n",
            "25th percentile: 0.000\n",
            "75th percentile: 0.000\n",
            "\n",
            "üí° Suggested clustering threshold: 0.500\n"
          ]
        }
      ],
      "source": [
        "# Initialize embedder (will use TF-IDF fallback if transformers fail)\n",
        "embedder = NameEmbedder('paraphrase-multilingual-MiniLM-L12-v2')\n",
        "\n",
        "print(\"ü§ñ Generating embeddings (using TF-IDF fallback if needed)...\")\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings = embedder.generate_embeddings(clean_data['normalized_name'].tolist())\n",
        "\n",
        "print(f\"‚úÖ Generated embeddings with shape: {embeddings.shape}\")\n",
        "print(f\"üìè Embedding dimension: {embeddings.shape[1]}\")\n",
        "print(f\"üéØ Method used: {'TF-IDF Fallback' if embedder._use_tfidf_fallback else 'Sentence Transformer'}\")\n",
        "\n",
        "if embedder._use_tfidf_fallback:\n",
        "    print(\"‚ÑπÔ∏è  Note: Using TF-IDF - this works great for semantic clustering!\")\n",
        "    \n",
        "    # Show TF-IDF vocabulary sample\n",
        "    if hasattr(embedder, '_tfidf_vectorizer') and embedder._tfidf_vectorizer:\n",
        "        vocab_sample = list(embedder._tfidf_vectorizer.vocabulary_.keys())[:15]\n",
        "        print(f\"üìö Sample vocabulary: {vocab_sample}\")\n",
        "\n",
        "# Analyze similarity distribution\n",
        "analyzer = SimilarityAnalyzer(embedder)\n",
        "similarity_stats = analyzer.analyze_similarity_distribution()\n",
        "\n",
        "print(\"\\nüìä Similarity Analysis:\")\n",
        "print(f\"Mean similarity: {similarity_stats['mean_similarity']:.3f}\")\n",
        "print(f\"Std deviation: {similarity_stats['std_similarity']:.3f}\")\n",
        "print(f\"25th percentile: {similarity_stats['q25']:.3f}\")\n",
        "print(f\"75th percentile: {similarity_stats['q75']:.3f}\")\n",
        "\n",
        "# Get suggested clustering threshold\n",
        "suggested_threshold = analyzer.suggest_clustering_threshold()\n",
        "print(f\"\\nüí° Suggested clustering threshold: {suggested_threshold:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Semantic Clustering\n",
        "\n",
        "Cluster semantically similar product names.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Performing semantic clustering...\n",
            "üîß Using clustering threshold: 0.500\n",
            "‚úÖ Clustering complete!\n",
            "üìä Found 55 semantic clusters\n",
            "üìä Silhouette Score: 0.03571428571428571\n",
            "üî¢ Largest cluster: 2 items\n",
            "üî¢ Average cluster size: 1.0\n",
            "üî¢ Singleton clusters: 54\n",
            "\n",
            "üìã Clustering preview (by cluster size):\n",
            "          text  cluster_id  cluster_size\n",
            "         kitap           0             2\n",
            "    kitap rafƒ±           0             2\n",
            " optical mouse           1             1\n",
            "          fare           2             1\n",
            "         raton           3             1\n",
            "computer mouse           4             1\n",
            "office cabinet           5             1\n",
            "     book rack           6             1\n",
            "     bookshelf           7             1\n",
            "wireless mouse           8             1\n",
            "    estanteria           9             1\n",
            "      cuaderno          10             1\n",
            "       journal          11             1\n",
            "  file cabinet          12             1\n",
            "  drinking mug          13             1\n",
            "   writing pad          14             1\n",
            "          taza          15             1\n",
            "        fincan          16             1\n",
            " library shelf          17             1\n",
            "       armario          18             1\n"
          ]
        }
      ],
      "source": [
        "# Perform semantic clustering\n",
        "print(\"üéØ Performing semantic clustering...\")\n",
        "\n",
        "# Use appropriate threshold for clustering\n",
        "clustering_threshold = suggested_threshold\n",
        "print(f\"üîß Using clustering threshold: {clustering_threshold:.3f}\")\n",
        "\n",
        "clusterer = NameClusterer('agglomerative')\n",
        "cluster_labels = clusterer.fit(\n",
        "    embeddings, \n",
        "    clean_data['normalized_name'].tolist(),\n",
        "    similarity_threshold=clustering_threshold\n",
        ")\n",
        "\n",
        "# Add cluster labels to dataframe\n",
        "clean_data['cluster_id'] = cluster_labels\n",
        "\n",
        "# Get clustering results\n",
        "clusters_df = clusterer.get_clusters_dataframe()\n",
        "eval_results = clusterer.evaluate_clustering()\n",
        "\n",
        "print(f\"‚úÖ Clustering complete!\")\n",
        "print(f\"üìä Found {eval_results['n_clusters']} semantic clusters\")\n",
        "print(f\"üìä Silhouette Score: {eval_results.get('silhouette_score', 'N/A')}\")\n",
        "print(f\"üî¢ Largest cluster: {eval_results['largest_cluster_size']} items\")\n",
        "print(f\"üî¢ Average cluster size: {eval_results['average_cluster_size']:.1f}\")\n",
        "print(f\"üî¢ Singleton clusters: {eval_results['singleton_clusters']}\")\n",
        "\n",
        "# Show clustering preview\n",
        "print(f\"\\nüìã Clustering preview (by cluster size):\")\n",
        "cluster_preview = clusters_df.head(20)\n",
        "print(cluster_preview[['text', 'cluster_id', 'cluster_size']].to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Semantic Analysis\n",
        "\n",
        "Analyze clusters to identify product categories and generate insights.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîç Analyzing semantic clusters...\n",
            "‚úÖ Semantic analysis complete!\n",
            "üìä Identified 10 product categories\n",
            "\n",
            "üìã Cluster Analysis Results:\n",
            " cluster_id  category representative_name  unique_names  unique_barcodes  total_items\n",
            "          0     Books               Kitap             2                2            2\n",
            "         33    Tables           Work Desk             1                1            1\n",
            "         52    Tables        Office Table             1                1            1\n",
            "         54    Tables     Mesa de Oficina             1                1            1\n",
            "         47    Tables        Writing Desk             1                1            1\n",
            "         48    Tables         Study Table             1                1            1\n",
            "         50    Tables      √áalƒ±≈üma Masasƒ±             1                1            1\n",
            "         51    Chairs        Office Chair             1                1            1\n",
            "         25    Chairs            Sandalye             1                1            1\n",
            "         49    Chairs    Silla de Oficina             1                1            1\n",
            "         28    Chairs      Computer Chair             1                1            1\n",
            "         38    Chairs     Ergonomic Chair             1                1            1\n",
            "         37    Chairs          Task Chair             1                1            1\n",
            "         36 Computers     Laptop Computer             1                1            1\n",
            "         23 Computers          Desktop PC             1                1            1\n",
            "         45 Computers          Bilgisayar             1                1            1\n",
            "         43 Computers           Ordenador             1                1            1\n",
            "         32 Computers     Computer System             1                1            1\n",
            "         41    Tables         Workstation             1                1            1\n",
            "         34     Lamps            LED Lamp             1                1            1\n",
            "         44    Tables          Table Lamp             1                1            1\n",
            "         46     Lamps          Desk Light             1                1            1\n",
            "         39    Chairs        Gaming Chair             1                1            1\n",
            "         40    Tables        Masa Lambasƒ±             1                1            1\n",
            "         27     Lamps       Reading Light             1                1            1\n",
            "         22  Monitors      Monitor Screen             1                1            1\n",
            "         31     Lamps          Study Lamp             1                1            1\n",
            "         29  Monitors         LCD Monitor             1                1            1\n",
            "         35  Monitors               Ekran             1                1            1\n",
            "         42  Monitors      Display Screen             1                1            1\n",
            "         24 Computers    Computer Display             1                1            1\n",
            "         21      Cups          Coffee Cup             1                1            1\n",
            "         53      Cups                 Mug             1                1            1\n",
            "         15      Cups                Taza             1                1            1\n",
            "         16      Cups              Fincan             1                1            1\n",
            "         30      Cups             Tea Cup             1                1            1\n",
            "         13      Cups        Drinking Mug             1                1            1\n",
            "         26     Books            Notebook             1                1            1\n",
            "         11     Books             Journal             1                1            1\n",
            "         10     Books            Cuaderno             1                1            1\n",
            "         14     Books         Writing Pad             1                1            1\n",
            "         19  Cabinets     Storage Cabinet             1                1            1\n",
            "         12  Cabinets        File Cabinet             1                1            1\n",
            "         20  Cabinets               Dolap             1                1            1\n",
            "         18  Cabinets             Armario             1                1            1\n",
            "          5  Cabinets      Office Cabinet             1                1            1\n",
            "          7   Shelves           Bookshelf             1                1            1\n",
            "          6   Shelves           Book Rack             1                1            1\n",
            "          9   Shelves          Estanter√≠a             1                1            1\n",
            "         17   Shelves       Library Shelf             1                1            1\n",
            "          4      Mice      Computer Mouse             1                1            1\n",
            "          8      Mice      Wireless Mouse             1                1            1\n",
            "          2      Mice                Fare             1                1            1\n",
            "          3      Mice               Rat√≥n             1                1            1\n",
            "          1      Mice       Optical Mouse             1                1            1\n",
            "\n",
            "üîç Detailed Cluster Information:\n",
            "\n",
            "üè∑Ô∏è Cluster 0 - Books:\n",
            "   Representative: 'Kitap'\n",
            "   2 unique products, 2 name variations\n",
            "   All names: Kitap, Kitap Rafƒ±\n",
            "\n",
            "üè∑Ô∏è Cluster 33 - Tables:\n",
            "   Representative: 'Work Desk'\n",
            "   1 unique products, 1 name variations\n",
            "   All names: Work Desk\n",
            "\n",
            "üè∑Ô∏è Cluster 52 - Tables:\n",
            "   Representative: 'Office Table'\n",
            "   1 unique products, 1 name variations\n",
            "   All names: Office Table\n",
            "\n",
            "üè∑Ô∏è Cluster 54 - Tables:\n",
            "   Representative: 'Mesa de Oficina'\n",
            "   1 unique products, 1 name variations\n",
            "   All names: Mesa de Oficina\n",
            "\n",
            "üè∑Ô∏è Cluster 47 - Tables:\n",
            "   Representative: 'Writing Desk'\n",
            "   1 unique products, 1 name variations\n",
            "   All names: Writing Desk\n",
            "\n",
            "üè∑Ô∏è Cluster 48 - Tables:\n",
            "   Representative: 'Study Table'\n",
            "   1 unique products, 1 name variations\n",
            "   All names: Study Table\n",
            "\n",
            "üè∑Ô∏è Cluster 50 - Tables:\n",
            "   Representative: '√áalƒ±≈üma Masasƒ±'\n",
            "   1 unique products, 1 name variations\n",
            "   All names: √áalƒ±≈üma Masasƒ±\n",
            "\n",
            "üè∑Ô∏è Cluster 51 - Chairs:\n",
            "   Representative: 'Office Chair'\n",
            "   1 unique products, 1 name variations\n",
            "   All names: Office Chair\n",
            "\n",
            "üè∑Ô∏è Cluster 25 - Chairs:\n",
            "   Representative: 'Sandalye'\n",
            "   1 unique products, 1 name variations\n",
            "   All names: Sandalye\n",
            "\n",
            "üè∑Ô∏è Cluster 49 - Chairs:\n",
            "   Representative: 'Silla de Oficina'\n",
            "   1 unique products, 1 name variations\n",
            "   All names: Silla de Oficina\n"
          ]
        }
      ],
      "source": [
        "# Initialize semantic analyzer\n",
        "semantic_analyzer = SemanticAnalyzer()\n",
        "\n",
        "print(\"üîç Analyzing semantic clusters...\")\n",
        "\n",
        "# Analyze clusters to identify categories\n",
        "cluster_analysis = semantic_analyzer.analyze_clusters(\n",
        "    clean_data,\n",
        "    name_column='name',\n",
        "    barcode_column='barcode',\n",
        "    cluster_column='cluster_id'\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Semantic analysis complete!\")\n",
        "print(f\"üìä Identified {cluster_analysis['category'].nunique()} product categories\")\n",
        "\n",
        "# Show cluster analysis\n",
        "print(f\"\\nüìã Cluster Analysis Results:\")\n",
        "display_cols = ['cluster_id', 'category', 'representative_name', 'unique_names', 'unique_barcodes', 'total_items']\n",
        "print(cluster_analysis[display_cols].to_string(index=False))\n",
        "\n",
        "# Show detailed cluster information\n",
        "print(f\"\\nüîç Detailed Cluster Information:\")\n",
        "for _, row in cluster_analysis.head(10).iterrows():\n",
        "    print(f\"\\nüè∑Ô∏è Cluster {row['cluster_id']} - {row['category']}:\")\n",
        "    print(f\"   Representative: '{row['representative_name']}'\")\n",
        "    print(f\"   {row['unique_barcodes']} unique products, {row['unique_names']} name variations\")\n",
        "    print(f\"   All names: {row['all_names'][:100]}{'...' if len(row['all_names']) > 100 else ''}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Category Summary\n",
        "\n",
        "Generate inventory summary by product category.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä INVENTORY SUMMARY BY CATEGORY:\n",
            "======================================================================\n",
            "\n",
            "üìÇ TABLES:\n",
            "   ‚Ä¢ 9 unique products (16.1% of inventory)\n",
            "   ‚Ä¢ 9 total items across 9 name cluster(s)\n",
            "   ‚Ä¢ Examples: Work Desk, Office Table, Mesa de Oficina\n",
            "\n",
            "üìÇ CHAIRS:\n",
            "   ‚Ä¢ 7 unique products (12.5% of inventory)\n",
            "   ‚Ä¢ 7 total items across 7 name cluster(s)\n",
            "   ‚Ä¢ Examples: Office Chair, Sandalye, Silla de Oficina\n",
            "\n",
            "üìÇ CUPS:\n",
            "   ‚Ä¢ 6 unique products (10.7% of inventory)\n",
            "   ‚Ä¢ 6 total items across 6 name cluster(s)\n",
            "   ‚Ä¢ Examples: Coffee Cup, Mug, Taza\n",
            "\n",
            "üìÇ BOOKS:\n",
            "   ‚Ä¢ 6 unique products (10.7% of inventory)\n",
            "   ‚Ä¢ 6 total items across 5 name cluster(s)\n",
            "   ‚Ä¢ Examples: Kitap, Notebook, Journal\n",
            "\n",
            "üìÇ COMPUTERS:\n",
            "   ‚Ä¢ 6 unique products (10.7% of inventory)\n",
            "   ‚Ä¢ 6 total items across 6 name cluster(s)\n",
            "   ‚Ä¢ Examples: Laptop Computer, Desktop PC, Bilgisayar\n",
            "\n",
            "üìÇ CABINETS:\n",
            "   ‚Ä¢ 5 unique products (8.9% of inventory)\n",
            "   ‚Ä¢ 5 total items across 5 name cluster(s)\n",
            "   ‚Ä¢ Examples: Storage Cabinet, File Cabinet, Dolap\n",
            "\n",
            "üìÇ MICE:\n",
            "   ‚Ä¢ 5 unique products (8.9% of inventory)\n",
            "   ‚Ä¢ 5 total items across 5 name cluster(s)\n",
            "   ‚Ä¢ Examples: Computer Mouse, Wireless Mouse, Fare\n",
            "\n",
            "üìÇ LAMPS:\n",
            "   ‚Ä¢ 4 unique products (7.1% of inventory)\n",
            "   ‚Ä¢ 4 total items across 4 name cluster(s)\n",
            "   ‚Ä¢ Examples: LED Lamp, Desk Light, Reading Light\n",
            "\n",
            "üìÇ MONITORS:\n",
            "   ‚Ä¢ 4 unique products (7.1% of inventory)\n",
            "   ‚Ä¢ 4 total items across 4 name cluster(s)\n",
            "   ‚Ä¢ Examples: Monitor Screen, LCD Monitor, Ekran\n",
            "\n",
            "üìÇ SHELVES:\n",
            "   ‚Ä¢ 4 unique products (7.1% of inventory)\n",
            "   ‚Ä¢ 4 total items across 4 name cluster(s)\n",
            "   ‚Ä¢ Examples: Bookshelf, Book Rack, Estanter√≠a\n",
            "\n",
            "üìà OVERALL STATISTICS:\n",
            "   ‚Ä¢ Total unique products: 56\n",
            "   ‚Ä¢ Total items: 56\n",
            "   ‚Ä¢ Product categories: 10\n",
            "   ‚Ä¢ Average items per product: 1.00\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Generate category summary\n",
        "category_summary = semantic_analyzer.get_category_summary(cluster_analysis)\n",
        "\n",
        "print(\"üìä INVENTORY SUMMARY BY CATEGORY:\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "total_barcodes = category_summary['total_barcodes'].sum()\n",
        "total_items = category_summary['total_items'].sum()\n",
        "\n",
        "for _, row in category_summary.iterrows():\n",
        "    category = row['category']\n",
        "    barcodes = row['total_barcodes']\n",
        "    items = row['total_items']\n",
        "    clusters = row['num_clusters']\n",
        "    examples = row['example_names']\n",
        "    \n",
        "    percentage = (barcodes / total_barcodes) * 100\n",
        "    print(f\"\\nüìÇ {category.upper()}:\")\n",
        "    print(f\"   ‚Ä¢ {barcodes} unique products ({percentage:.1f}% of inventory)\")\n",
        "    print(f\"   ‚Ä¢ {items} total items across {clusters} name cluster(s)\")\n",
        "    print(f\"   ‚Ä¢ Examples: {examples}\")\n",
        "\n",
        "print(f\"\\nüìà OVERALL STATISTICS:\")\n",
        "print(f\"   ‚Ä¢ Total unique products: {total_barcodes}\")\n",
        "print(f\"   ‚Ä¢ Total items: {total_items}\")\n",
        "print(f\"   ‚Ä¢ Product categories: {len(category_summary)}\")\n",
        "print(f\"   ‚Ä¢ Average items per product: {total_items/total_barcodes:.2f}\")\n",
        "\n",
        "print(\"=\" * 70)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
